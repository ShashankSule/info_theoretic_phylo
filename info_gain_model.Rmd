---
title: "Information gain model for trees"
author: "Shashank Sule"
date: "14/06/2021"
output:
  github_document:
    pandoc_args: --webtex
---

```{r, echo=FALSE,include=FALSE}
knitr::opts_knit$set(root.dir = '/Users/shashanksule/Documents/info_theoretic_phylo/')
library("adegenet")
library("ape")
library("apTreeshape")
library("BoSSA")
library("diversitree")
library("pegas")
library("phangorn")
library("phylobase")
#library("phyloch")
library("seqinr")
library("readr")
source("utilities.R")
library("progress")
library("ggplot2")
library("phyclust")
library("TreeDist")
library("TreeTools")
library("dplyr")
library("parallel")
library("adephylo")
library("profvis")
```

# The model

Let $\mathcal{S}$ be a set of OTU's and let $T(\mathcal{S})$ be a binary tree associated with $\mathcal{S}$. If $|\mathcal{S}| = n$ then the number of bifurcations in $T(\mathcal{S})$ is $n-1$ so the task is to figure out the bifurcations of $T(\mathcal{S})$ (or more directly, figure out a set of sensible bifurcations $B_i$ to make a tree with $\mathcal{S}$ as tips or leaves). In APE lingo, these bifurcations are called "splits". 

The information gain model of bifurcations/splits/partitions is as follows: Let $\mathcal{S}$ be a set of OTU's and $\mathcal{P} = A \sqcup B$ any partition. Supposing that $A$ are realizations of a random process $X$ and $B$ are realizations of a random process $Y$, then the information of $\mathcal{P}$ is $J(\mathcal{P}) := J(X,Y)$ where $J$ is some meaningful information theoretic function of $X$ and $Y$.

# Some comments about the choice of $J$

Of course, this is a very general model but it's worth spending some time about the choices of $J$. So far we've come up with the following: 

1. Information gain 

This model is used to make decision trees from given data $\mathcal{S}$ containing data from a set of classes (typically it's a binary set). Let $A \sqcup B = \mathcal{S}$ and $P_A = |A|/|\mathcal{S}|$. Then let $Z \sim X_\eta$ where $\eta = 1$ with probability $P_A$ and $2$ with probability $1 - P_A$. Considering $\mathcal{S}$ as a set of samples from $Z$ we can actually compute $I(Z;\eta) = H(Z) - H(Z \mid \eta) = H(\mathcal{S}) - P_A H(A) - (1 - P_{A}) H(B)$. This is the corrected version of the formula at the bottom of page 3 in `info_theory_ideas`. Using the notation of $x_i$ from this document, we may also write it as $I(x_0; (x_1, x_2)) = H(x_0) - \alpha H(x_1) - (1-\alpha)H(x_2)$ where $\alpha$ is the proportion of taxa in the partition $x_1$. Here the expression "$(x_1, x_2)$" is to be understood as the _tree_ $(x_1, x_2)$ in Newick and not the joint distribution $(x_1, x_2)$. We'll have to be careful about this notation from now on. But computationally this strategy gives the most sensible trees for the simple case of $n$ sequences of length 1. 

2. Symmetrised cross entropy

Let $p$ be the distribution of $x_1$ and $q$ the distribution of $x_2$. Then the cross entropy is $H(p,q) := -\sum_{x}p(x)\log_2 q(x)$. Note that $H(p,q) \neq H(q,p)$ in general so we let $J(X,Y) = J(x_1, x_2) = H(p,q) + H(q,p)$. The cross entropy is a value that compares how far $q$ is from $p$ and in source coding quantifies the minimum expected code length when the underlying probability distribution of the source is misunderstood as $q$ instead of $p$. 

# Algorithm based on Information Gain

In the case where $\mathcal{S}$ is aligned molecular sequence data of length 1 (basically all we have is each species represented through a single nucleotide), we assume that $X_1$ is a random variable which takes values in a four-element set (i.e $\{a,c,g,t\}$) and $A$ is the set of realizations of $X_1$ (and similarly for a random variable $X_2$ whose realisations are represented by $B$). Let $\eta$ represent a Bernoulli random variable taking values $1$ and $2$ with parameter $\alpha = |A|/|\mathcal{S}|$. Then letting $Z = X_\eta$ the mutual between $Z$ and the tree $\eta$ can be estimated as

$$I(Z, \eta) \approx I(\mathcal{S}; (A,B)) = H(\mathcal{S}) - \frac{|A|}{|\mathcal{S}|}H(A) - \frac{|B|}{|\mathcal{S}|}H(B)$$ 

The optimal partition is a solution to 

$$
\mathcal{P}^* = \text{argmax}_{(A,B)}\,I(\mathcal{S};(A,B))
$$

The algorithm `infotree` for making a tree $T(\mathcal{S})$ with input $\mathcal{S}$ is as follows: 

a) Compute the optimal partition of $\mathcal{S}$ as $\mathcal{P}^* = A \sqcup B$. 
b) Run `infotree` on $A$ and $B$ as input.

# Implementation 

Let's try this out on a small example. First we make a tree with say 9 tips that evolves by the Yule model where the probability of a bifurcation is 1/2. 

```{r}
t <- rtreeshape(1,9,model = "yule")

plot(as.phylo(t[[1]]))
```

Using `simseq` we'll make sequences of length 1 representing the tree

```{r}
seqs <- simSeq(as.phylo(t[[1]]),l=12, type = "DNA")
```

Now let's set up the main body of the algorithm 

```{r}
mutual_info <- function(partition, sequence, pos){
# inputs:
# partition -- boolean denoting the partitions
# sequence -- dataframe of type DNAbin or phyDat with each row an aligned sequence
# pos -- integer denoting the position in the sequence

# output:
# I(partition)

#computing p(x \oplus y)
  
p_xy <- base.freq(as.DNAbin(sequence))

A <- sequence[partition,pos]
B <- sequence[!partition,pos]

# Computing p(x)

p_x <- base.freq(as.DNAbin(A))
p_a <- length(A)/length(sequence)

# Computing p(y)

p_y <- base.freq(as.DNAbin(B))
p_b <- length(B)/length(sequence)

h_xy <- 0 
h_x <- 0 
h_y <- 0 

# Computing p(x,y)

I <- 0

# for(i in c(1:4)){
#   if(p_xy[i] !=0){
#     h_xy <- h_xy -p_xy[i]*log2(p_xy[i])
#   }
#   if(p_x[i] != 0){
#     h_x <- h_x -p_x[i]*log2(p_x[i])
#   }
#   if(p_y[i] != 0){
#     h_y <- h_y -p_y[i]*log2(p_y[i])
#   }
# }

# I <- h_xy - p_a*h_x - p_b*h_y

for(i in c(1:4)){
  if(p_x[i] !=0 ){
    I <- I - p_b*p_y[i]*log2(p_x[i])
  }
  if(p_y[i] != 0){
    I <- I - p_a*p_x[i]*log2(p_y[i])
  }
}
return(I)
}

```



```{r}
infopart <- function(sequence){
#input: 
# sequence -- aligned sequence in DNAbin or phyDat 
# output: 
# Newick string representing minimum information gain tree


# if there are only two sequences return dichotomous tree
if(length(sequence) == 1){
 tree_string <- names(sequence)[1] 
} else if(length(sequence) == 2){
  tree_string <- paste("(", names(sequence)[1], ", ", names(sequence)[2], ")", sep = "")
} else{
  
  # There are more than two sequences so we must find the optimal partition. 
  # Initialize the data 
  
  partition <- as.logical(splitset(length(sequence))[2,])
  I <- 0   
  for(j in 1:attr(sequence, "nr")){
          I <- I + mutual_info(partition, sequence, j)
  }
  max_val <- I
  max_part <- partition
  
  for(i in 2:(2^(length(sequence))-1)){ # Run through all possible partitions
    I <- 0 
          # Compute overall mutual information 
    #print(paste("computing the ",i,"th partition")) 
    partition <- as.logical(splitset(length(sequence))[i,])
    
        for(j in 1:attr(sequence, "nr")){
            I <- I + mutual_info(partition, sequence, j)
        }
    
    print(paste("I =",I))
    
    if(I < max_val){
      max_val <- I 
      max_part <- partition
    }
  }
   print(paste("The partition is ", max_part))
   left_sequence <- sequence[max_part,]
   right_sequence <- sequence[!max_part,]
   left_string <- infopart(left_sequence)
   right_string <- infopart(right_sequence)
   
   tree_string <- paste("(",left_string,", ",right_string,")", sep = "")

   
}

  return(tree_string)
}
```

## Codon variant

Instead of computing over nucleotides (and the gap character) we compute over codons, which are sequences of three nucleotides. First we preprocess data to get it into codon structure 

```{r}
sequence <- ReadCharacters("coiii.nex")
#sequence <- sequence[,1:6]
```


```{r}
padding <- ncol(sequence) %% 3 

if(padding !=0 ){
   for(i in 1:padding){
      sequence <- cbind(sequence, rep("-", nrow(sequence)))
    }  
}

codon_sequence <- matrix(splitseq(t(sequence)), nrow = nrow(sequence), ncol = ncol(sequence)/3, byrow = TRUE)
rownames(codon_sequence) <- rownames(sequence)
codon_sequence
```

```{r}

```


Ok. Now that we've processed it into codon form we write a codon-style information-gain method for every codon site, partition and all. 

```{r}

# Full code: 

# sequence <- codon_sequence[,2]
# partition <- as.logical(splitset(10)[6,])

info_gain_codon_site <- function(sequence, partition) {
    A <- sequence[partition]
    B <- sequence[!partition]
    w_x <- length(A) / length(sequence)
    w_y <- length(B) / length(sequence)
    p_x <- table(A)/length(A)
    p_y <- table(B)/length(B)
    p_xy <- table(sequence)/length(sequence)
    IG <- Entropy(p_xy) - w_x*Entropy(p_x) - w_y*Entropy(p_y)
    return(IG)
}

vi_codon_site <- function(sequence, partition) {
  A <- sequence[partition]
    B <- sequence[!partition]
    w_x <- length(A) / length(sequence)
    w_y <- length(B) / length(sequence)
    p_x <- table(A)/length(A)
    p_y <- table(B)/length(B)
    p_xy <- table(sequence)/length(sequence)
    VI <- 2*Entropy(p_xy) - Entropy(p_x) - Entropy(p_y)
    return(VI)
}

info_gain_codon <- function(sequence, partition) {
  part_line <- as.logical(partition)
  IG <- c(0,0)
  site_data <- asplit(sequence, 2)
  #I <- sum(as.numeric(lapply(site_data, info_gain, partition = part_line)))
  IG <- sum(apply(sequence, 2, info_gain_codon_site, partition = part_line))
  
  #print(paste("I =", I))
  return(IG)
}

vi_codon <- function(sequence, partition) {
  part_line <- as.logical(partition)
  VI <- c(0,0)
  VI <- sum(apply(sequence, 2, vi_codon_site, partition = part_line))
  
  #print(paste("IG =", I))
  return(VI)
}

```

```{r}
infotree_codon <- function(sequence) {
  #input:
  # sequence -- matrix of characters
  # output:
  # Newick string representing minimum information gain tree
  # if there are only two sequences return dichotomous tree
  l = DIM(sequence)
  names = row.names(sequence)
  num_sites = ncol(sequence)
  
  if (l == 1) {
    tree_string <- names[1]
  } else if (l == 2) {
    part_matrix <- splitset(l)[c(2:(2 ^ (l - 1))), ]
    branch <- 2*vi_codon(sequence, part_matrix)/num_sites 
    tree_string <-
      paste("(", names[1], ":", branch/2, ", ", names[2], ":", branch/2, ")", sep = "")
    cat("Done!\n")
  } else{
    # There are more than two sequences so we must find the optimal partition.
    
    cat("Partitioning...")
    part_matrix <- splitset(l)[c(2:(2 ^ (l - 1))), ]
    parts <- asplit(part_matrix,1)
    res <- mclapply(parts, info_gain_codon, sequence = sequence)
    max_val <- max(as.numeric(res))
    max_part <- part_matrix[which.max(as.numeric(res)), ]
    #res <- apply(part_matrix, 1, max_info, seq = sequence)
    #max_val <- max(res)
    #max_part <- part_matrix[which.max(res), ]
    branch <- vi_codon(sequence, max_part)/num_sites
    cur_partition <- as.logical(max_part)
    left_sequence <- sequence[cur_partition, , drop = FALSE]
    right_sequence <- sequence[!cur_partition, , drop = FALSE]
    left_string <- infotree(left_sequence)
    right_string <- infotree(right_sequence)
    
    tree_string <-
      paste("(", left_string, ":", branch/2, ", ", right_string, ":", branch/2, ")", sep = "")
    
  }
  return(tree_string)
}
```

Let's clock the old against the new 

```{r}
partition <- as.logical(splitset(10)[232,])
```


```{r}
start <- Sys.time()
infotree(sequence)
end <- Sys.time()
print(end - start)
```

```{r}
profvis({infotree(sequence)})

```

# Results

## Sequences of length 1 

We check the trees produced by information gain and symmetrized cross entropy for the 9 tips with sequence length 1. 

```{r,echo=FALSE}
IG_tree_string <- paste(infopart(seqs), ";", sep="")
```


```{r, echo = FALSE}
image(as.DNAbin(seqs))
#layout(matrix(c(1,2), 1, 2))
#image(as.DNAbin(seqs))
plot(read.tree(text = IG_tree_string))
```

It's a totally sensible tree as it is able to differentiate species with different nucleotides. Clearly there are three distinct classes: $\{1,3,4,6\}, \{2\},$ and $\{5,8,9\}$. Starting from the leaves, each tip is first sorted into its own class before it is merged with tips from other classes. So this is a sensible dichotomous tree on our data. 

## Sequences of length n 

We assume that the distributions on different sites are independent.

```{r}
seqs2 <- simSeq(as.phylo(t[[1]]),l=12, type = "DNA")
```

Let's visualize this sequence first: 

```{r, echo = FALSE}
image(as.DNAbin(seqs2))
```

Let's make the IG tree! 

```{r,echo=FALSE}
IG2_tree_string <- paste(infopart(seqs2), ";", sep="")
```

```{r, echo = FALSE}
plot(read.tree(text = IG2_tree_string))
```

We also have the following toy sequence from Press et al, stored in the file `press_codes.phy`. 

```{r, echo = FALSE}
# codes <- c("cggttgggagct",
#            "aggtcgtgaggt",
#            "tggttggggttt",
#            "tgggtgcgagtt",
#            "acgtttgggtga",
#            "aaggttggggaa",
#            "gtctttcgggtg",
#            "cacttgcggggg",
#            "gcgcggtgcagc",
#            "aggcggtgcggg",
#            "gggcggggcggg",
#            "gggcgctgcggg",
#            "ggacggaggctg",
#            "gggtgggagctg",
#            "aggaggctgatg",
#            "tggcggatgatg")
# 
# write.dna(lapply(codes,s2c),"press_codes.phy")
```

```{r}
```


```{r}
read.dna("press_codes.phy")
```

We'll convert it to `phyDat` to start crunching trees: 

```{r}
trial_DNA <- as.phyDat(read.dna("press_codes.phy"))

trial_DNA
```

Let's make a tree using `infopart`! Let's actually avoid computing the whole tree for the data since we'd have to make $2^15 - 1$ computations. Instead, let's assume the first (and the most costly) split: ((0:7),(8:15)). Now we'll run `infopart` on these partitions and check the results with Figures 16.6.4-16.6.6 in Press et al. 

```{r}
layout(matrix(c(1,2), 1, 2))
plot(read.tree(text = paste(infopart(trial_DNA[1:8,]), ";", sep="")))
plot(read.tree(text = paste(infopart(trial_DNA[9:16,]), ";", sep="")))
```

Let's go for the `coiii.nex` dataset found in Cummings et al. 1995! 

```{r}
# reading coiii.nex as phyDat: 

raw_data <- ReadCharacters("coiii.nex")

# reading coiii.nex as DNAbin: 

#raw_data <- read.nexus.data("coiii.nex")

```

